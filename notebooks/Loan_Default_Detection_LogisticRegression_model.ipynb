{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries for Analysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats.contingency import association\n",
    "import math\n",
    "from sklearn.preprocessing import power_transform\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score, precision_score,recall_score,confusion_matrix,fbeta_score\n",
    "from sklearn.preprocessing import OrdinalEncoder,RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer,KNNImputer,SimpleImputer\n",
    "from sklearn.decomposition import SparsePCA,PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_amnt        term  int_rate  installment grade sub_grade  \\\n",
      "0    10000.0   36 months     11.44       329.48     B        B4   \n",
      "1     8000.0   36 months     11.99       265.68     B        B5   \n",
      "2    15600.0   36 months     10.49       506.97     B        B3   \n",
      "3     7200.0   36 months      6.49       220.65     A        A2   \n",
      "4    24375.0   60 months     17.27       609.33     C        C5   \n",
      "\n",
      "                 emp_title emp_length home_ownership  annual_inc  ...  \\\n",
      "0                Marketing  10+ years           RENT    117000.0  ...   \n",
      "1          Credit analyst     4 years       MORTGAGE     65000.0  ...   \n",
      "2             Statistician   < 1 year           RENT     43057.0  ...   \n",
      "3          Client Advocate    6 years           RENT     54000.0  ...   \n",
      "4  Destiny Management Inc.    9 years       MORTGAGE     55000.0  ...   \n",
      "\n",
      "  open_acc pub_rec revol_bal revol_util total_acc  initial_list_status  \\\n",
      "0     16.0     0.0   36369.0       41.8      25.0                    w   \n",
      "1     17.0     0.0   20131.0       53.3      27.0                    f   \n",
      "2     13.0     0.0   11987.0       92.2      26.0                    f   \n",
      "3      6.0     0.0    5472.0       21.5      13.0                    f   \n",
      "4     13.0     0.0   24584.0       69.8      43.0                    f   \n",
      "\n",
      "  application_type  mort_acc  pub_rec_bankruptcies  \\\n",
      "0       INDIVIDUAL       0.0                   0.0   \n",
      "1       INDIVIDUAL       3.0                   0.0   \n",
      "2       INDIVIDUAL       0.0                   0.0   \n",
      "3       INDIVIDUAL       0.0                   0.0   \n",
      "4       INDIVIDUAL       1.0                   0.0   \n",
      "\n",
      "                                             address  \n",
      "0     0174 Michelle Gateway\\r\\nMendozaberg, OK 22690  \n",
      "1  1076 Carney Fort Apt. 347\\r\\nLoganmouth, SD 05113  \n",
      "2  87025 Mark Dale Apt. 269\\r\\nNew Sabrina, WV 05113  \n",
      "3            823 Reid Ford\\r\\nDelacruzside, MA 00813  \n",
      "4             679 Luna Roads\\r\\nGreggshire, VA 11650  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "## Data Loading and Initial Inspection\n",
    "\"\"\"\n",
    "Dataset : logistic_regression.csv\n",
    "\n",
    "\"\"\"\n",
    "df = pd.read_csv('../data/logistic_regression.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.098682940017767\n"
     ]
    }
   ],
   "source": [
    "# As loan_status is the target variable , Checking if there is imbalance in loan_status\n",
    "loan_status_freq = df['loan_status'].value_counts()\n",
    "target_imbalance = loan_status_freq['Fully Paid']/loan_status_freq['Charged Off']\n",
    "print(target_imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying train test split before EDA. As its a imbalanced classification with 4:1 ratio applying straify\n",
    "X_train_validation, X_test_final, y_train_validation, y_test_final = train_test_split(df.drop(['loan_status'],axis = 1),df['loan_status'],random_state=40,test_size=0.1,stratify=df['loan_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_validation,y_train,y_validation = train_test_split(X_train_validation,y_train_validation,random_state=40,test_size=0.1,stratify=y_train_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train  (320784, 26)\n",
      "y_train  (320784,)\n",
      "X_validation  (35643, 26)\n",
      "y_validation  (35643,)\n",
      "X_test  (39603, 26)\n",
      "y_test  (39603,)\n"
     ]
    }
   ],
   "source": [
    "# Checking lengths of datasets\n",
    "print('X_train ',X_train.shape)\n",
    "print('y_train ',y_train.shape)\n",
    "print('X_validation ',X_validation.shape)\n",
    "print('y_validation ',y_validation.shape)\n",
    "print('X_test ',X_test_final.shape)\n",
    "print('y_test ',y_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanju\\Downloads\\Data_Analytics_Projects\\LoantapAnalysis\\.virtualenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sanju\\Downloads\\Data_Analytics_Projects\\LoantapAnalysis\\.virtualenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.81021286,  1.41605861,  0.57898055, ..., -0.21475251,\n",
       "         0.18593412, -0.25350122],\n",
       "       [-0.9232165 ,  2.09387859, -1.92191432, ...,  0.08666308,\n",
       "         0.07881045,  0.20948448],\n",
       "       [ 1.19361143, -2.89680118, -1.20134756, ..., -0.0212977 ,\n",
       "         0.03693095, -0.1419411 ],\n",
       "       ...,\n",
       "       [-1.76885635, -0.60523999,  0.66441857, ...,  0.08718215,\n",
       "        -0.09399867, -0.0696243 ],\n",
       "       [-1.05575514, -1.52390176,  0.19273947, ..., -0.42341593,\n",
       "         0.17600811, -0.03045699],\n",
       "       [ 0.94729087,  1.02876056,  0.51351647, ...,  0.1662929 ,\n",
       "        -0.05906222,  0.04681927]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data = X_train.copy()\n",
    "y_encoder = LabelEncoder( )\n",
    "y_encoder.fit(y_train)\n",
    "y_encoder.classes_= np.array(['Fully Paid','Charged Off'])\n",
    "y_train_encoded = y_encoder.transform(y_train[loan_data.index])\n",
    "def empl_length(x):\n",
    "    if x!=x:\n",
    "        return None\n",
    "    if x[:2]=='10':\n",
    "        return 10\n",
    "    if x[0]=='<':\n",
    "        return 0\n",
    "    else:\n",
    "        return int(x[0])\n",
    "loan_data['emp_length_num'] = loan_data['emp_length'].apply(empl_length)\n",
    "loan_data['term_num'] = loan_data['term'].apply(lambda x: int(x[1:3])).apply(int)\n",
    "state_col = loan_data['address'].apply(lambda x: x.replace(',','').split()[-2])\n",
    "state_encoder = OneHotEncoder()\n",
    "state_encoded = state_encoder.fit_transform(pd.DataFrame(state_col))\n",
    "state_df = pd.DataFrame.sparse.from_spmatrix(state_encoded,columns=['state_'+i for i in state_encoder.categories_[0]],index = loan_data.index)\n",
    "loan_data = loan_data.join(state_df)\n",
    "pincode_col = loan_data['address'].apply(lambda x: x.replace(',','').split()[-1])\n",
    "pincode_encoder = OneHotEncoder()\n",
    "pincode_encoded = pincode_encoder.fit_transform(pd.DataFrame(pincode_col))\n",
    "pincode_df = pd.DataFrame.sparse.from_spmatrix(pincode_encoded,columns=['pincode_'+i for i in pincode_encoder.categories_[0]],index = loan_data.index)\n",
    "loan_data = loan_data.join(pincode_df)\n",
    "homeown = loan_data['home_ownership']\n",
    "homeown_encoder = OneHotEncoder(min_frequency=1000)\n",
    "homeown_prp = homeown_encoder.fit_transform(pd.DataFrame(homeown))\n",
    "homeown_prp_df = pd.DataFrame.sparse.from_spmatrix(homeown_prp,columns=homeown_encoder.get_feature_names_out(),index = loan_data.index)\n",
    "loan_data= loan_data.join(homeown_prp_df)\n",
    "verif_encoder = OneHotEncoder()\n",
    "verif_prp = verif_encoder.fit_transform(pd.DataFrame(loan_data['verification_status']))\n",
    "verif_prp_df = pd.DataFrame.sparse.from_spmatrix(verif_prp,columns=verif_encoder.get_feature_names_out(),index = loan_data.index)\n",
    "loan_data= loan_data.join(verif_prp_df)\n",
    "ils_encoder = OneHotEncoder()\n",
    "ils_prp = ils_encoder.fit_transform(pd.DataFrame(loan_data['initial_list_status']))\n",
    "ils_prp_df = pd.DataFrame.sparse.from_spmatrix(ils_prp,columns=ils_encoder.get_feature_names_out(),index = loan_data.index)\n",
    "loan_data= loan_data.join(ils_prp_df)\n",
    "loan_subgrade = loan_data['sub_grade']\n",
    "loan_subgrade_ordinal_encoder = OrdinalEncoder(categories=[['G5', 'G4', 'G3', 'G2', 'G1', 'F5', 'F4', 'F3', 'F2', 'F1', 'E5',\n",
    "       'E4', 'E3', 'E2', 'E1', 'D5', 'D4', 'D3', 'D2', 'D1', 'C5', 'C4',\n",
    "       'C3', 'C2', 'C1', 'B5', 'B4', 'B3', 'B2', 'B1', 'A5', 'A4', 'A3',\n",
    "       'A2', 'A1']])\n",
    "loan_data['sub_grade_enc'] = (loan_subgrade_ordinal_encoder.fit_transform(pd.DataFrame(loan_subgrade)))\n",
    "loan_subgrade_target_encoder = TargetEncoder(random_state=40)\n",
    "k = 1.2\n",
    "loan_data['sub_grade_enc'] = (loan_data['sub_grade_enc']**k)/pd.Series(loan_subgrade_target_encoder.fit_transform(pd.DataFrame(loan_subgrade),y_train_encoded).reshape(1,-1)[0],index = loan_subgrade.index)\n",
    "emp_title_encoder = OneHotEncoder(min_frequency=1000,handle_unknown='infrequent_if_exist')\n",
    "emp_title_prp = emp_title_encoder.fit_transform(pd.DataFrame(loan_data['emp_title']))\n",
    "emp_title_prp_df = pd.DataFrame.sparse.from_spmatrix(emp_title_prp,columns=emp_title_encoder.get_feature_names_out(),index = loan_data.index)\n",
    "loan_data= loan_data.join(emp_title_prp_df)\n",
    "loan_data['acc_open_perc'] = loan_data['open_acc']/(loan_data['total_acc']+1)\n",
    "purpose_encoder = OneHotEncoder(min_frequency=1000)\n",
    "purpose_prp = purpose_encoder.fit_transform(pd.DataFrame(loan_data['purpose']))\n",
    "purpose_prp_df = pd.DataFrame.sparse.from_spmatrix(purpose_prp,columns=purpose_encoder.get_feature_names_out(),index = loan_data.index)\n",
    "loan_data= loan_data.join(purpose_prp_df)\n",
    "loan_data['credit_yr'] = pd.to_datetime(loan_data['earliest_cr_line'],format = \"%b-%Y\").apply(lambda x: x.year) \n",
    "loan_data['credit_month'] = pd.to_datetime(loan_data['earliest_cr_line'],format = \"%b-%Y\").apply(lambda x: x.month )\n",
    "loan_data['issue_yr'] = pd.to_datetime(loan_data['issue_d'],format = \"%b-%Y\").apply(lambda x: x.year)  \n",
    "loan_data['issue_month'] = pd.to_datetime(loan_data['issue_d'],format = \"%b-%Y\").apply(lambda x: x.month )\n",
    "title_encoder = OneHotEncoder(min_frequency=1000,handle_unknown='infrequent_if_exist')\n",
    "title_prp = title_encoder.fit_transform(pd.DataFrame(loan_data['title']))\n",
    "title_prp_df = pd.DataFrame.sparse.from_spmatrix(title_prp,columns=title_encoder.get_feature_names_out(),index = loan_data.index)\n",
    "loan_data= loan_data.join(title_prp_df)\n",
    "\n",
    "X_train_prp = loan_data.drop(columns = ['term','installment','grade','emp_length','sub_grade','emp_title','home_ownership','verification_status','issue_d','purpose','title','earliest_cr_line','address','initial_list_status','application_type'])\n",
    "scaler_1 = StandardScaler()\n",
    "X_train_prp_s = pd.DataFrame(scaler_1.fit_transform(X_train_prp),index = X_train_prp.index,columns=X_train_prp.columns)\n",
    "imp_mean = SimpleImputer(strategy='mean')\n",
    "X_train_prp_imputed = pd.DataFrame(imp_mean.fit_transform(X_train_prp_s),columns=imp_mean.get_feature_names_out(),index = X_train_prp_s.index)\n",
    "pca = PCA(n_components=120)\n",
    "X_train_prp_pca = pca.fit_transform(X_train_prp_imputed)\n",
    "X_train_prp_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X_test,y_test):\n",
    "    y_test_encoded = y_encoder.transform(y_test[X_test.index])\n",
    "    X_test['emp_length_num'] = X_test['emp_length'].apply(empl_length)\n",
    "    X_test['term_num'] = X_test['term'].apply(lambda x: int(x[1:3])).apply(int)\n",
    "    state_col = X_test['address'].apply(lambda x: x.replace(',','').split()[-2])\n",
    "    state_encoded = state_encoder.transform(pd.DataFrame(state_col))\n",
    "    state_df = pd.DataFrame.sparse.from_spmatrix(state_encoded,columns=['state_'+i for i in state_encoder.categories_[0]],index = X_test.index)\n",
    "    X_test = X_test.join(state_df)\n",
    "    pincode_col = X_test['address'].apply(lambda x: x.replace(',','').split()[-1])\n",
    "    pincode_encoded = pincode_encoder.transform(pd.DataFrame(pincode_col))\n",
    "    pincode_df = pd.DataFrame.sparse.from_spmatrix(pincode_encoded,columns=['pincode_'+i for i in pincode_encoder.categories_[0]],index = X_test.index)\n",
    "    X_test = X_test.join(pincode_df)\n",
    "    homeown = X_test['home_ownership']\n",
    "    homeown_prp = homeown_encoder.transform(pd.DataFrame(homeown))\n",
    "    homeown_prp_df = pd.DataFrame.sparse.from_spmatrix(homeown_prp,columns=homeown_encoder.get_feature_names_out(),index = X_test.index)\n",
    "    X_test= X_test.join(homeown_prp_df)\n",
    "    verif_prp = verif_encoder.transform(pd.DataFrame(X_test['verification_status']))\n",
    "    verif_prp_df = pd.DataFrame.sparse.from_spmatrix(verif_prp,columns=verif_encoder.get_feature_names_out(),index = X_test.index)\n",
    "    X_test= X_test.join(verif_prp_df)\n",
    "    ils_prp = ils_encoder.transform(pd.DataFrame(X_test['initial_list_status']))\n",
    "    ils_prp_df = pd.DataFrame.sparse.from_spmatrix(ils_prp,columns=ils_encoder.get_feature_names_out(),index = X_test.index)\n",
    "    X_test= X_test.join(ils_prp_df)\n",
    "    loan_subgrade = X_test['sub_grade']\n",
    "    X_test['sub_grade_enc'] = (loan_subgrade_ordinal_encoder.transform(pd.DataFrame(loan_subgrade)))\n",
    "    X_test['sub_grade_enc'] = (X_test['sub_grade_enc']**k)/pd.Series(loan_subgrade_target_encoder.transform(pd.DataFrame(loan_subgrade)).reshape(1,-1)[0],index = loan_subgrade.index)\n",
    "    emp_title_prp = emp_title_encoder.transform(pd.DataFrame(X_test['emp_title']))\n",
    "    emp_title_prp_df = pd.DataFrame.sparse.from_spmatrix(emp_title_prp,columns=emp_title_encoder.get_feature_names_out(),index = X_test.index)\n",
    "    X_test= X_test.join(emp_title_prp_df)\n",
    "    X_test['acc_open_perc'] = X_test['open_acc']/(X_test['total_acc']+1)\n",
    "    purpose_prp = purpose_encoder.transform(pd.DataFrame(X_test['purpose']))\n",
    "    purpose_prp_df = pd.DataFrame.sparse.from_spmatrix(purpose_prp,columns=purpose_encoder.get_feature_names_out(),index = X_test.index)\n",
    "    X_test= X_test.join(purpose_prp_df)\n",
    "    X_test['credit_yr'] = pd.to_datetime(X_test['earliest_cr_line'],format = \"%b-%Y\").apply(lambda x: x.year) \n",
    "    X_test['credit_month'] = pd.to_datetime(X_test['earliest_cr_line'],format = \"%b-%Y\").apply(lambda x: x.month )\n",
    "    X_test['issue_yr'] = pd.to_datetime(X_test['issue_d'],format = \"%b-%Y\").apply(lambda x: x.year)  \n",
    "    X_test['issue_month'] = pd.to_datetime(X_test['issue_d'],format = \"%b-%Y\").apply(lambda x: x.month )\n",
    "    title_prp = title_encoder.transform(pd.DataFrame(X_test['title']))\n",
    "    title_prp_df = pd.DataFrame.sparse.from_spmatrix(title_prp,columns=title_encoder.get_feature_names_out(),index = X_test.index)\n",
    "    X_test= X_test.join(title_prp_df)\n",
    "    X_test_prp = X_test.drop(columns = ['term','installment','grade','emp_length','sub_grade','emp_title','home_ownership','verification_status','issue_d','purpose','title','earliest_cr_line','address','initial_list_status','application_type'])\n",
    "    X_test_prp_s = pd.DataFrame(scaler_1.transform(X_test_prp),index = X_test_prp.index,columns=X_test_prp.columns)\n",
    "    X_test_prp_imputed = pd.DataFrame(imp_mean.transform(X_test_prp_s),columns=imp_mean.get_feature_names_out(),index = X_test_prp_s.index)\n",
    "    X_test_prp_pca = pca.transform(X_test_prp_imputed)\n",
    "    return X_test_prp_pca,y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanju\\Downloads\\Data_Analytics_Projects\\LoantapAnalysis\\.virtualenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "c:\\Users\\sanju\\Downloads\\Data_Analytics_Projects\\LoantapAnalysis\\.virtualenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:877: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_test_prp_pca,y_test_encoded = preprocess(X_test_final,y_test_final)\n",
    "X_validation_prp_pca,y_validation_encoded = preprocess(X_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanju\\Downloads\\Data_Analytics_Projects\\LoantapAnalysis\\.virtualenv\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8623372736794853\n",
      "Precision: 0.6440719630045015\n",
      "ROC-AUC: 0.9077119601156327\n",
      "Recall 0.6663275848366844\n",
      "Fbeta 0.6519106352777548\n"
     ]
    }
   ],
   "source": [
    "model_1 = LogisticRegression(n_jobs=-1,penalty='l2',solver='saga',random_state=40,class_weight={0:1,1:2.5})\n",
    "model_1.fit(X_train_prp_pca,y_train_encoded)\n",
    "print(\"Accuracy:\", accuracy_score(y_train_encoded,model_1.predict(X_train_prp_pca)))\n",
    "print(\"Precision:\", precision_score(y_train_encoded,model_1.predict(X_train_prp_pca)))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_train_encoded,model_1.predict_proba(X_train_prp_pca)[:,1]))\n",
    "print(\"Recall\", recall_score(y_train_encoded,model_1.predict(X_train_prp_pca)))\n",
    "print(\"Fbeta\", fbeta_score(y_train_encoded,model_1.predict(X_train_prp_pca),beta = 0.75,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8609544651123643\n",
      "Precision: 0.6416144745998609\n",
      "ROC-AUC: 0.9057915261425948\n",
      "Recall 0.6594192533257045\n",
      "Fbeta 0.6479123449086177\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_validation_encoded,model_1.predict(X_validation_prp_pca)))\n",
    "print(\"Precision:\", precision_score(y_validation_encoded,model_1.predict(X_validation_prp_pca)))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_validation_encoded,model_1.predict_proba(X_validation_prp_pca)[:,1]))\n",
    "print(\"Recall\", recall_score(y_validation_encoded,model_1.predict(X_validation_prp_pca)))\n",
    "print(\"Fbeta\", fbeta_score(y_validation_encoded,model_1.predict(X_validation_prp_pca),beta = 0.75,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8621821579173296\n",
      "Precision: 0.6438270835928741\n",
      "ROC-AUC: 0.9066972207715824\n",
      "Recall 0.6653791682760396\n",
      "Fbeta 0.6514230972848968\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test_encoded,model_1.predict(X_test_prp_pca)))\n",
    "print(\"Precision:\", precision_score(y_test_encoded,model_1.predict(X_test_prp_pca)))\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_test_encoded,model_1.predict_proba(X_test_prp_pca)[:,1]))\n",
    "print(\"Recall\", recall_score(y_test_encoded,model_1.predict(X_test_prp_pca)))\n",
    "print(\"Fbeta\", fbeta_score(y_test_encoded,model_1.predict(X_test_prp_pca),beta = 0.75,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
